---
title: "AutoScore-Ordinal: An Interpretable Machine Learning Framework for Generating Scoring Models for Ordinal Outcomes"
author: ""
date: ""
output: 
  md_document:
    variant: gfm
---

```{r setup, include=FALSE}
set.seed(1234)
library(knitr)
opts_chunk$set(echo = TRUE, collapse = TRUE, cache = TRUE)
```

# **AutoScore-Ordinal Introduction**

### Description

<!--
AutoScore is a novel machine learning framework to automate the development of
interpretable clinical scoring models. AutoScore consists of six modules: 1)
variable ranking with machine learning, 2) variable transformation, 3) score
derivation, 4) model selection, 5) domain knowledge-based score fine-tuning, and
6) performance evaluation. The AutoScore is elaborated in the article
(<http://dx.doi.org/10.2196/21798>) and its flowchart is shown in the following
figure. AutoScore could seamlessly generate risk scores using a parsimonious set
of variables, which can be easily implemented and validated in clinical
practice. Moreover, it enables users to build transparent and interpretable
clinical scores quickly in a straightforward manner.
-->

### Functions and pipeline

The five pipeline functions:  `AutoScore_Ordinal_rank()`,
`AutoScore_Ordinal_parsimony()`, `AutoScore_Ordinal_weighting()`,
`AutoScore_fine_Ordinal_tuning()` and `AutoScore_Ordinal_testing()` constitute
the 5-step AutoScore-based process for generating point-based clinical scores.
This 5-step process gives users the flexibility of customization (e.g.,
determining the final list of variables according to the parsimony plot, and
fine-tuning the cutoffs in variable transformation). Please follow the
step-by-step instructions (in Demos) to build your own scores.

* STEP(i): `AutoScore_Ordinal_rank()` - Rank variables with random forest for
multiclass classification (AutoScore-Ordinal Module 1)
* STEP(ii): `AutoScore_Ordinal_parsimony()` - Select the best model with
parsimony plot (AutoScore-Ordinal Modules 2+3+4)
* STEP(iii): `AutoScore_Ordinal_weighting()` - Generate the initial score with
the final list of variables (Re-run AutoScore-Ordinal Modules 2+3)
* STEP(iv): `AutoScore_Ordinal_fine_tuning()` - Fine-tune the score by revising
`cut_vec` with domain knowledge (AutoScore-Ordinal Module 5)
* STEP(v): `AutoScore_Ordinal_testing()` - Evaluate the final score with
multiclass ROC analysis (AutoScore-Ordinal Module 6)

Note: This is just the initial version of the AutoScore-Ordinal. Further version
will be developed and updated.

### Citation

<!--
Xie F, Chakraborty B, Ong MEH, Goldstein BA, Liu N. AutoScore: A Machine Learning-Based Automatic Clinical Score Generator and Its Application to Mortality Prediction Using Electronic Health Records. JMIR Medical Informatics 2020;8(10):e21798 (<http://dx.doi.org/10.2196/21798>)
-->

### Contact

- Yilin Ning (Email: <yilin.ning@duke-nus.edu.sg>)
- Nan Liu (Email: <liu.nan@duke-nus.edu.sg>)

# **AutoScore-Ordinal Demonstration**

<h id="Demo0">

## **Install the package and prepare data**

### Install from GitHub:

```{r basic, eval=FALSE}
# From Github
install.packages("devtools")
library(devtools)
install_github(repo = "nliulab/AutoScoreOrdinal")
```


### Load R package

```{r library, results = "hide", warning=FALSE, message=FALSE}
library(AutoScoreOrdinal)
```

### Load data 
- Read data from CSV or Excel files.
- For this demo, use the integrated `sample_data_ordinal` in the package.
- `sample_data_ordinal` has 20000 simulated samples, with similar distribution
to the data used in the paper.
```{r}
data("sample_data_ordinal")
head(sample_data_ordinal)
```

### Data preprocessing (Users to check the following)
- Handle missing values (AutoScore requires a complete dataset).
- Remove special characters from variable names, e.g., `[`, `]`, `(`, `)`,`,`.
(Suggest using `_` to replace them if needed)
- Name of the variable should be unique and not entirely included by other variable names.
- Ensure that the dependent variable is named "label" (make sure no variables
using the same name).
- Independent variables should be numeric (class: num/int) or categorical (class: factor/logic).
- Handle outliers (optional).
- Check variable distribution (optional).

### AutoScore preprocessing (Users to check the following)

- Check if data fulfil the basic requirement by AutoScore.
- Fix the problem if you see any warnings.
```{r}
check_data(sample_data_ordinal)
```

- Modify your data to ensure no warning messages.

<h id="Demo">

## **AutoScore-Ordinal Demo**

In this Demo, we demonstrate the use of AutoScore-Ordinal on a comparably large
dataset where separate training and validation sets are available. Please note
that it is just a demo using simulated data, and thus, the result might not be
clinically meaningful.

### Prepare training, validation, and test datasets
- Option 1: Prepare three separate datasets to train, validate, and test models.
- Option 2: Use demo codes below to randomly split your dataset into training, validation, and test datasets (70%, 10%, 20%, respectively).
```{r}
set.seed(1234)
out_split <- split_data(data = sample_data_ordinal, ratio = c(0.7, 0.1, 0.2), 
                        strat_by_label = TRUE)
train_set <- out_split$train_set
validation_set <- out_split$validation_set
test_set <- out_split$test_set
```


### STEP(i): Generate variable ranking list (AutoScore Module 1)
- `ntree`: Number of trees in the random forest algorithm (Default: 100).
```{r}
ranking <- AutoScore_Ordinal_rank(train_set = train_set, ntree = 100)
```

### STEP(ii): Select the best model with parsimony plot (AutoScore Modules 2+3+4)
- `nmin`: Minimum number of selected variables (Default: 1).
- `nmax`: Maximum number of selected variables (Default: 20).
- `categorize`: Methods for categorizing continuous variables. Options include `"quantile"` or `"kmeans"` (Default: `"quantile"`).
- `quantiles`: Predefined quantiles to convert continuous variables to categorical ones. (Default: `c(0, 0.05, 0.2, 0.8, 0.95, 1)`) Available if `categorize = "quantile"`.
- `max_cluster`: The max number of cluster (Default: 5). Available if `categorize = "kmeans"`.
- `max_score`: Maximum total score (Default: 100).
- `auc_lim_min`: y-axis limits (min) of the parsimony plot (Default: 0.5)
- `auc_lim_max`: y-axis limits (max) of the parsimony plot (Default: "adaptive")

```{r}
mAUC <- AutoScore_Ordinal_parsimony(
  train_set,
  validation_set,
  rank = ranking,
  max_score = 100,
  n_min = 1,
  n_max = 20,
  categorize = "quantile",
  quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), 
  auc_lim_min = 0
)
```

- Determine the optimal number of variables (`num_var`) based on the parsimony plot obtained in STEP(ii). 
- The final list of variables is the first `num_var` variables in the ranked list `ranking` obtained in STEP(i). 
- Optional: User can adjust the finally included variables `final_variables` based on the clinical preferences and knowledge.
```{r}
# Example 1: Top 6 variables are selected
num_var <- 6
final_variables <- names(ranking[1:num_var])

# Example 2: Top 9 variables are selected
num_var <- 9
final_variables <- names(ranking[1:num_var])

# Example 3: Top 6 variables, the 13th and 16th variable are selected
final_variables <- names(ranking[c(1:6, 13, 16)])
```


```{r finalvariab2,include=FALSE}
final_variables <- names(ranking[c(1:6, 13, 16)])
```

### STEP(iii): Generate initial scores with the final list of variables (Re-run AutoScore Modules 2+3)
- Generate `cut_vec` with current cutoffs of continuous variables, which can be fine-tuned in STEP(iv).
```{r weighting,  warning = FALSE}
cut_vec <- AutoScore_Ordinal_weighting(
  train_set = train_set, validation_set = validation_set, 
  final_variables = final_variables, 
  max_score = 100,
  categorize = "quantile",
  quantiles = c(0, 0.05, 0.2, 0.8, 0.95, 1), n_boot = 100
)

```

### STEP(iv): Fine-tune the initial score generated in STEP(iii) (AutoScore Module 5 & Re-run AutoScore Modules 2+3) 
- Revise `cut_vec` with domain knowledge to update the scoring table (AutoScore Module 5).
- Re-run AutoScore Modules 2+3 to generate the updated scores.
- Users can choose any cutoff values and/or any number of categories, but are suggested to choose numbers close to the automatically determined values.

```{r}
## For example, we have current cutoffs of continuous variable: Age 
## ==============  ===========  =====
## variable        interval     point
## ==============  ===========  =====
## Age                 <27          0  
##                     [27,46)      2  
##                     [46,78)     12  
##                     [78,87)     16 
##                     >=87        19 
```

- Current cutoffs:`c(46, 78, 88)`. We can fine tune the cutoffs as follows:
```{r}
# Example 1: rounding to a nice number
cut_vec$Age <- c(25, 45, 75, 90)

# Example 2: changing cutoffs according to clinical knowledge or preference 
cut_vec$Age <- c(25, 50, 75, 90)

# Example 3: combining categories
cut_vec$Age <- c(45, 75, 90)
```


The mAUC and 95% bootstrap CI are reported after fine-tuning. The default number
of bootstrap samples is 100.
```{r scoring, warning = FALSE}
cut_vec$ED_LOS <- c(2 / 3, 4 / 3, 4, 6)
cut_vec$Age <- c(25, 45, 75, 85)
cut_vec$Pulse <- c(60, 70, 95, 115)
cut_vec$CREATININE <- c(45, 60, 135, 595)
cut_vec$BICARBONATE <- c(17, 20, 25, 28)
cut_vec$BP_Systolic <- c(100, 110, 150, 180)
scoring_table <- AutoScore_Ordinal_fine_tuning(train_set,
                                               validation_set,
                                               final_variables,
                                               cut_vec,
                                               max_score = 100, n_boot = 100)

```

### STEP(v): Evaluate final risk scores on test dataset (AutoScore Module 6)
The mAUC and generalised c-index are reported for the test set, with 95%
bootstrap CI computed from 100 bootstrap samples (default).
```{r}
pred_score <- AutoScore_Ordinal_testing(
  test_set = test_set, 
  final_variables = final_variables, 
  cut_vec = cut_vec, 
  score_table = scoring_table, 
  with_label = TRUE, n_boot = 100
)
head(pred_score)
```

- Users could use the `pred_score` for further analysis or export it as the CSV to other software.

```{r, eval=FALSE}
write.csv(pred_score, file = "pred_score.csv")
```

<!---
To-do:
- [done] Add bootstrap CI for mAUC
- [done] Remove threshold from scoring table
- Give a function to produce mapping table from training set
- Give a function to make bar plot
-->
